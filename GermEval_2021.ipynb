{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lined-interference",
   "metadata": {},
   "source": [
    "# Textklassifikation am Beispiel [GermEval 2021](https://germeval2021toxic.github.io/SharedTask/)\n",
    "\n",
    "Dieses Notebook ist eine adaptierte Version des Beispielskripts [examples/pytorch/text-classification/run_glue.py](https://github.com/huggingface/transformers/blob/master/examples/pytorch/text-classification/run_glue.py) von Huggingface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "under-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "# Copyright 2020 The HuggingFace Inc. team. All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "direct-patient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/tljh/user/lib/python3.7/site-packages (0.10.30)\n",
      "Requirement already satisfied: transformers in /opt/tljh/user/lib/python3.7/site-packages (4.5.0)\n",
      "Requirement already satisfied: datasets in /opt/tljh/user/lib/python3.7/site-packages (1.6.2)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in /opt/tljh/user/lib/python3.7/site-packages (from wandb) (0.17.3)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/tljh/user/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /opt/tljh/user/lib/python3.7/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/tljh/user/lib/python3.7/site-packages (from wandb) (3.13.0)\n",
      "Requirement already satisfied: PyYAML in /opt/tljh/user/lib/python3.7/site-packages (from wandb) (5.3.1)\n",
      "Requirement already satisfied: Click>=7.0 in /opt/tljh/user/lib/python3.7/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/tljh/user/lib/python3.7/site-packages (from wandb) (3.1.7)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/tljh/user/lib/python3.7/site-packages (from wandb) (5.7.2)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /opt/tljh/user/lib/python3.7/site-packages (from wandb) (5.0.0)\n",
      "Requirement already satisfied: pathtools in /opt/tljh/user/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/tljh/user/lib/python3.7/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/tljh/user/lib/python3.7/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/tljh/user/lib/python3.7/site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/tljh/user/lib/python3.7/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/tljh/user/lib/python3.7/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/tljh/user/lib/python3.7/site-packages (from transformers) (1.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/tljh/user/lib/python3.7/site-packages (from transformers) (4.48.2)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/tljh/user/lib/python3.7/site-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/tljh/user/lib/python3.7/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: packaging in /opt/tljh/user/lib/python3.7/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: filelock in /opt/tljh/user/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /opt/tljh/user/lib/python3.7/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/tljh/user/lib/python3.7/site-packages (from transformers) (2020.7.14)\n",
      "Requirement already satisfied: dill in /opt/tljh/user/lib/python3.7/site-packages (from datasets) (0.3.2)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /opt/tljh/user/lib/python3.7/site-packages (from datasets) (0.0.8)\n",
      "Requirement already satisfied: fsspec in /opt/tljh/user/lib/python3.7/site-packages (from datasets) (2021.4.0)\n",
      "Requirement already satisfied: xxhash in /opt/tljh/user/lib/python3.7/site-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /opt/tljh/user/lib/python3.7/site-packages (from datasets) (1.0.1)\n",
      "Requirement already satisfied: pandas in /opt/tljh/user/lib/python3.7/site-packages (from datasets) (1.1.2)\n",
      "Requirement already satisfied: multiprocess in /opt/tljh/user/lib/python3.7/site-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: urllib3>=1.10.0 in /opt/tljh/user/lib/python3.7/site-packages (from sentry-sdk>=0.4.0->wandb) (1.25.10)\n",
      "Requirement already satisfied: certifi in /opt/tljh/user/lib/python3.7/site-packages (from sentry-sdk>=0.4.0->wandb) (2020.6.20)\n",
      "Requirement already satisfied: setuptools in /opt/tljh/user/lib/python3.7/site-packages (from protobuf>=3.12.0->wandb) (41.0.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/tljh/user/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/tljh/user/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/tljh/user/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/tljh/user/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/tljh/user/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: joblib in /opt/tljh/user/lib/python3.7/site-packages (from sacremoses->transformers) (0.15.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/tljh/user/lib/python3.7/site-packages (from pandas->datasets) (2020.1)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /opt/tljh/user/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.4)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jupyter-gawron.christian/.netrc\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb transformers datasets\n",
    "!wandb login aee0ebe6843a7b138378e5ace3fdad105494724f\n",
    "\n",
    "!test -e GermEval21_Toxic_Train.csv || wget -O GermEval21_Toxic_Train.csv https://raw.githubusercontent.com/cgawron/GermEval_2021/main/GermEval21_Toxic_Train.csv?token=AADCWPFIZXF6EM2QWVRICL3AUQHAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "artistic-trinidad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "announced-morning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=GermEval_2021\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=GermEval_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "supreme-plenty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_LOG_MODEL=true\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_LOG_MODEL=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "linear-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Finetuning the library models for sequence classification on GermEval2021.\"\"\"\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint, is_main_process\n",
    "from transformers.utils import check_min_version\n",
    "\n",
    "\n",
    "# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n",
    "check_min_version(\"4.5.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "finished-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "task_to_keys = {\n",
    "    \"germeval2021\": (\"comment_text\", None),\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "\n",
    "    Using `HfArgumentParser` we can turn this class\n",
    "    into argparse arguments to be able to specify them on\n",
    "    the command line.\n",
    "    \"\"\"\n",
    "\n",
    "    task_name: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The name of the task to train on: \" + \", \".join(task_to_keys.keys())},\n",
    "    )\n",
    "    max_seq_length: int = field(\n",
    "        default=128,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated, sequences shorter will be padded.\"\n",
    "        },\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached preprocessed datasets or not.\"}\n",
    "    )\n",
    "    pad_to_max_length: bool = field(\n",
    "        default=True,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to pad all samples to `max_seq_length`. \"\n",
    "            \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n",
    "        },\n",
    "    )\n",
    "    max_train_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    max_eval_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    max_predict_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    train_file: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"A csv or a json file containing the training data.\"}\n",
    "    )\n",
    "    validation_file: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"A csv or a json file containing the validation data.\"}\n",
    "    )\n",
    "    test_file: Optional[str] = field(default=None, metadata={\"help\": \"A csv or a json file containing the test data.\"})\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.task_name is not None:\n",
    "            self.task_name = self.task_name.lower()\n",
    "            if self.task_name not in task_to_keys.keys():\n",
    "                raise ValueError(f\"Unknown task {self.task_name}, you should pick one in \" + \", \".join(task_to_keys.keys()))\n",
    "        elif self.train_file is None or self.validation_file is None:\n",
    "            raise ValueError(\"Need either a GLUE task or a training/validation file.\")\n",
    "        else:\n",
    "            train_extension = self.train_file.split(\".\")[-1]\n",
    "            assert train_extension in [\"csv\", \"json\"], \"`train_file` should be a csv or a json file.\"\n",
    "            validation_extension = self.validation_file.split(\".\")[-1]\n",
    "            assert (\n",
    "                validation_extension == train_extension\n",
    "            ), \"`validation_file` should have the same extension (csv or json) as `train_file`.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "approved-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: str = field(\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n",
    "    )\n",
    "    use_fast_tokenizer: bool = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"},\n",
    "    )\n",
    "    model_revision: str = field(\n",
    "        default=\"main\",\n",
    "        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n",
    "    )\n",
    "    use_auth_token: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Will use the token generated when running `transformers-cli login` (necessary to use this script \"\n",
    "            \"with private models).\"\n",
    "        },\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-linux",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Dataset for the [GermAval2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments](https://germeval2021toxic.github.io/SharedTask/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-alfred",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "brave-running",
   "metadata": {},
   "source": [
    "## Passing configuration\n",
    "\n",
    "For this notebook, we use a `dict()` of configuration values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fantastic-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "\n",
    "    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n",
    "    model_args, data_args, training_args = parser.parse_dict(config)\n",
    "\n",
    "    # Detecting last checkpoint.\n",
    "    last_checkpoint = None\n",
    "    if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n",
    "        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "            raise ValueError(\n",
    "                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "                \"Use --overwrite_output_dir to overcome.\"\n",
    "            )\n",
    "\n",
    "    # Setup logging\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        handlers=[logging.StreamHandler(sys.stdout)],\n",
    "    )\n",
    "    logger.setLevel(logging.INFO if is_main_process(training_args.local_rank) else logging.WARN)\n",
    "\n",
    "    # Log on each process the small summary:\n",
    "    logger.warning(\n",
    "        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "        + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    "    )\n",
    "    # Set the verbosity to info of the Transformers logger (on main process only):\n",
    "    if is_main_process(training_args.local_rank):\n",
    "        transformers.utils.logging.set_verbosity_info()\n",
    "        transformers.utils.logging.enable_default_handler()\n",
    "        transformers.utils.logging.enable_explicit_format()\n",
    "    logger.info(f\"Training/evaluation parameters {training_args}\")\n",
    "\n",
    "    # Set seed before initializing model.\n",
    "    set_seed(training_args.seed)\n",
    "\n",
    "    # Get the datasets: you can either provide your own CSV/JSON training and evaluation files (see below)\n",
    "    # or specify a GLUE benchmark task (the dataset will be downloaded automatically from the datasets Hub).\n",
    "    #\n",
    "    # For CSV/JSON files, this script will use as labels the column called 'label' and as pair of sentences the\n",
    "    # sentences in columns called 'sentence1' and 'sentence2' if such column exists or the first two columns not named\n",
    "    # label if at least two columns are provided.\n",
    "    #\n",
    "    # If the CSVs/JSONs contain only one non-label column, the script does single sentence classification on this\n",
    "    # single column. You can easily tweak this behavior (see below)\n",
    "    #\n",
    "    # In distributed training, the load_dataset function guarantee that only one local process can concurrently\n",
    "    # download the dataset.\n",
    "    if data_args.task_name == 'germeval2021':\n",
    "        # Downloading and loading a dataset from the hub.\n",
    "        datasets = germeval2021\n",
    "    else:\n",
    "        # Loading a dataset from your local files.\n",
    "        # CSV/JSON training and evaluation files are needed.\n",
    "        data_files = {\"train\": data_args.train_file, \"validation\": data_args.validation_file}\n",
    "\n",
    "        # Get the test dataset: you can provide your own CSV/JSON test file (see below)\n",
    "        # when you use `do_predict` without specifying a GLUE benchmark task.\n",
    "        if training_args.do_predict:\n",
    "            if data_args.test_file is not None:\n",
    "                train_extension = data_args.train_file.split(\".\")[-1]\n",
    "                test_extension = data_args.test_file.split(\".\")[-1]\n",
    "                assert (\n",
    "                    test_extension == train_extension\n",
    "                ), \"`test_file` should have the same extension (csv or json) as `train_file`.\"\n",
    "                data_files[\"test\"] = data_args.test_file\n",
    "            else:\n",
    "                raise ValueError(\"Need either a GLUE task or a test file for `do_predict`.\")\n",
    "\n",
    "        for key in data_files.keys():\n",
    "            logger.info(f\"load a local file for {key}: {data_files[key]}\")\n",
    "\n",
    "        if data_args.train_file.endswith(\".csv\"):\n",
    "            # Loading a dataset from local csv files\n",
    "            datasets = load_dataset(\"csv\", data_files=data_files, cache_dir=model_args.cache_dir)\n",
    "        else:\n",
    "            # Loading a dataset from local json files\n",
    "            datasets = load_dataset(\"json\", data_files=data_files, cache_dir=model_args.cache_dir)\n",
    "    # See more about loading any type of standard or custom dataset at\n",
    "    # https://huggingface.co/docs/datasets/loading_datasets.html.\n",
    "\n",
    "    # Labels\n",
    "    if data_args.task_name is not None:\n",
    "        is_regression = data_args.task_name == \"stsb\"\n",
    "        if not is_regression:\n",
    "            label_list = datasets[\"train\"].features[\"label\"].names\n",
    "            num_labels = len(label_list)\n",
    "        else:\n",
    "            num_labels = 1\n",
    "    else:\n",
    "        # Trying to have good defaults here, don't hesitate to tweak to your needs.\n",
    "        is_regression = datasets[\"train\"].features[\"label\"].dtype in [\"float32\", \"float64\"]\n",
    "        if is_regression:\n",
    "            num_labels = 1\n",
    "        else:\n",
    "            # A useful fast method:\n",
    "            # https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.unique\n",
    "            label_list = datasets[\"train\"].unique(\"label\")\n",
    "            label_list.sort()  # Let's sort it for determinism\n",
    "            num_labels = len(label_list)\n",
    "\n",
    "    # Load pretrained model and tokenizer\n",
    "    #\n",
    "    # In distributed training, the .from_pretrained methods guarantee that only one local process can concurrently\n",
    "    # download model & vocab.\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "        num_labels=num_labels,\n",
    "        finetuning_task=data_args.task_name,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "        revision=model_args.model_revision,\n",
    "        use_auth_token=True if model_args.use_auth_token else None,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "        use_fast=model_args.use_fast_tokenizer,\n",
    "        revision=model_args.model_revision,\n",
    "        use_auth_token=True if model_args.use_auth_token else None,\n",
    "    )\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "        config=config,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "        revision=model_args.model_revision,\n",
    "        use_auth_token=True if model_args.use_auth_token else None,\n",
    "    )\n",
    "\n",
    "    # Preprocessing the datasets\n",
    "    if data_args.task_name is not None:\n",
    "        sentence1_key, sentence2_key = task_to_keys[data_args.task_name]\n",
    "    else:\n",
    "        # Again, we try to have some nice defaults but don't hesitate to tweak to your use case.\n",
    "        non_label_column_names = [name for name in datasets[\"train\"].column_names if name != \"label\"]\n",
    "        if \"sentence1\" in non_label_column_names and \"sentence2\" in non_label_column_names:\n",
    "            sentence1_key, sentence2_key = \"sentence1\", \"sentence2\"\n",
    "        else:\n",
    "            if len(non_label_column_names) >= 2:\n",
    "                sentence1_key, sentence2_key = non_label_column_names[:2]\n",
    "            else:\n",
    "                sentence1_key, sentence2_key = non_label_column_names[0], None\n",
    "\n",
    "    # Padding strategy\n",
    "    if data_args.pad_to_max_length:\n",
    "        padding = \"max_length\"\n",
    "    else:\n",
    "        # We will pad later, dynamically at batch creation, to the max sequence length in each batch\n",
    "        padding = False\n",
    "\n",
    "    # Some models have set the order of the labels to use, so let's make sure we do use it.\n",
    "    label_to_id = None\n",
    "    if (\n",
    "        model.config.label2id != PretrainedConfig(num_labels=num_labels).label2id\n",
    "        and data_args.task_name is not None\n",
    "        and not is_regression\n",
    "    ):\n",
    "        # Some have all caps in their config, some don't.\n",
    "        label_name_to_id = {k.lower(): v for k, v in model.config.label2id.items()}\n",
    "        if list(sorted(label_name_to_id.keys())) == list(sorted(label_list)):\n",
    "            label_to_id = {i: int(label_name_to_id[label_list[i]]) for i in range(num_labels)}\n",
    "        else:\n",
    "            logger.warning(\n",
    "                \"Your model seems to have been trained with labels, but they don't match the dataset: \",\n",
    "                f\"model labels: {list(sorted(label_name_to_id.keys()))}, dataset labels: {list(sorted(label_list))}.\"\n",
    "                \"\\nIgnoring the model labels as a result.\",\n",
    "            )\n",
    "    elif data_args.task_name is None and not is_regression:\n",
    "        label_to_id = {v: i for i, v in enumerate(label_list)}\n",
    "\n",
    "    if data_args.max_seq_length > tokenizer.model_max_length:\n",
    "        logger.warning(\n",
    "            f\"The max_seq_length passed ({data_args.max_seq_length}) is larger than the maximum length for the\"\n",
    "            f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\"\n",
    "        )\n",
    "    max_seq_length = min(data_args.max_seq_length, tokenizer.model_max_length)\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        # Tokenize the texts\n",
    "        args = (\n",
    "            (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "        )\n",
    "        result = tokenizer(*args, padding=padding, max_length=max_seq_length, truncation=True)\n",
    "\n",
    "        # Map labels to IDs (not necessary for GLUE tasks)\n",
    "        if label_to_id is not None and \"label\" in examples:\n",
    "            result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]\n",
    "        return result\n",
    "\n",
    "    datasets = datasets.map(preprocess_function, batched=True, load_from_cache_file=not data_args.overwrite_cache)\n",
    "    if training_args.do_train:\n",
    "        if \"train\" not in datasets:\n",
    "            raise ValueError(\"--do_train requires a train dataset\")\n",
    "        train_dataset = datasets[\"train\"]\n",
    "        if data_args.max_train_samples is not None:\n",
    "            train_dataset = train_dataset.select(range(data_args.max_train_samples))\n",
    "\n",
    "    if training_args.do_eval:\n",
    "        if \"validation\" not in datasets and \"validation_matched\" not in datasets:\n",
    "            raise ValueError(\"--do_eval requires a validation dataset\")\n",
    "        eval_dataset = datasets[\"validation_matched\" if data_args.task_name == \"mnli\" else \"validation\"]\n",
    "        if data_args.max_eval_samples is not None:\n",
    "            eval_dataset = eval_dataset.select(range(data_args.max_eval_samples))\n",
    "\n",
    "    if training_args.do_predict or data_args.task_name is not None or data_args.test_file is not None:\n",
    "        if \"test\" not in datasets and \"test_matched\" not in datasets:\n",
    "            raise ValueError(\"--do_predict requires a test dataset\")\n",
    "        predict_dataset = datasets[\"test_matched\" if data_args.task_name == \"mnli\" else \"test\"]\n",
    "        if data_args.max_predict_samples is not None:\n",
    "            predict_dataset = predict_dataset.select(range(data_args.max_predict_samples))\n",
    "\n",
    "    # Log a few random samples from the training set:\n",
    "    if training_args.do_train:\n",
    "        for index in random.sample(range(len(train_dataset)), 3):\n",
    "            logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")\n",
    "\n",
    "    # Get the metric function\n",
    "    #if data_args.task_name is not None:\n",
    "    # metric = load_metric(\"glue\", data_args.task_name)\n",
    "    # TODO: When datasets metrics include regular accuracy, make an else here and remove special branch from\n",
    "    # compute_metrics\n",
    "\n",
    "    # You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
    "    # predictions and label_ids field) and has to return a dictionary string to float.\n",
    "    def compute_metrics(p: EvalPrediction):\n",
    "        preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "        preds = np.squeeze(preds) if is_regression else np.argmax(preds, axis=1)\n",
    "        accuracy = (preds == p.label_ids).astype(np.float32).mean().item()\n",
    "        metrics = { \"accuracy\": accuracy }\n",
    "        for val, key in enumerate(label_list):\n",
    "            tp = ((preds == p.label_ids) * (preds == val)).sum().item()\n",
    "            fp = ((preds != p.label_ids) * (preds == val)).sum().item()\n",
    "            fn = ((preds != p.label_ids) * (preds != val)).sum().item()\n",
    "       \n",
    "            precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "            recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "            metrics[f\"precision_{key}\"] = precision\n",
    "            metrics[f\"recall_{key}\"] = recall\n",
    "            metrics[f\"f1_{key}\"] = f1\n",
    "        \n",
    "        avg_pre = sum([ metrics[f\"precision_{key}\"] for key in label_list ]) / len(label_list)\n",
    "        avg_rec = sum([ metrics[f\"recall_{key}\"] for key in label_list ]) / len(label_list)\n",
    "        avg_f1 = 2 * avg_pre * avg_rec / (avg_pre + avg_rec)\n",
    "        metrics['precision_ma'] = avg_pre\n",
    "        metrics['recall_ma'] = avg_rec\n",
    "        metrics['f1_ma'] = avg_f1\n",
    "        return metrics\n",
    "\n",
    "    # Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.\n",
    "    if data_args.pad_to_max_length:\n",
    "        data_collator = default_data_collator\n",
    "    elif training_args.fp16:\n",
    "        data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8)\n",
    "    else:\n",
    "        data_collator = None\n",
    "\n",
    "    # Initialize our Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset if training_args.do_train else None,\n",
    "        eval_dataset=eval_dataset if training_args.do_eval else None,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "\n",
    "    # Training\n",
    "    if training_args.do_train:\n",
    "        checkpoint = None\n",
    "        if last_checkpoint is not None:\n",
    "            checkpoint = last_checkpoint\n",
    "        train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "        metrics = train_result.metrics\n",
    "        max_train_samples = (\n",
    "            data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n",
    "        )\n",
    "        metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n",
    "        trainer.save_model()  # Saves the tokenizer too for easy upload\n",
    "\n",
    "        trainer.log_metrics(\"train\", metrics)\n",
    "        trainer.save_metrics(\"train\", metrics)\n",
    "        trainer.save_state()\n",
    "\n",
    "    # Evaluation\n",
    "    if training_args.do_eval:\n",
    "        logger.info(\"*** Evaluate ***\")\n",
    "\n",
    "        # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "        tasks = [data_args.task_name]\n",
    "        eval_datasets = [eval_dataset]\n",
    "        if data_args.task_name == \"mnli\":\n",
    "            tasks.append(\"mnli-mm\")\n",
    "            eval_datasets.append(datasets[\"validation_mismatched\"])\n",
    "\n",
    "        for eval_dataset, task in zip(eval_datasets, tasks):\n",
    "            metrics = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "\n",
    "            max_eval_samples = (\n",
    "                data_args.max_eval_samples if data_args.max_eval_samples is not None else len(eval_dataset)\n",
    "            )\n",
    "            metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n",
    "\n",
    "            trainer.log_metrics(\"eval\", metrics)\n",
    "            trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "    if training_args.do_predict:\n",
    "        logger.info(\"*** Predict ***\")\n",
    "\n",
    "        # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "        tasks = [data_args.task_name]\n",
    "        predict_datasets = [predict_dataset]\n",
    "        if data_args.task_name == \"mnli\":\n",
    "            tasks.append(\"mnli-mm\")\n",
    "            predict_datasets.append(datasets[\"test_mismatched\"])\n",
    "\n",
    "        for predict_dataset, task in zip(predict_datasets, tasks):\n",
    "            # Removing the `label` columns because it contains -1 and Trainer won't like that.\n",
    "            predict_dataset.remove_columns_(\"label\")\n",
    "            predictions = trainer.predict(predict_dataset, metric_key_prefix=\"predict\").predictions\n",
    "            predictions = np.squeeze(predictions) if is_regression else np.argmax(predictions, axis=1)\n",
    "\n",
    "            output_predict_file = os.path.join(training_args.output_dir, f\"predict_results_{task}.txt\")\n",
    "            if trainer.is_world_process_zero():\n",
    "                with open(output_predict_file, \"w\") as writer:\n",
    "                    logger.info(f\"***** Predict results {task} *****\")\n",
    "                    writer.write(\"index\\tprediction\\n\")\n",
    "                    for index, item in enumerate(predictions):\n",
    "                        if is_regression:\n",
    "                            writer.write(f\"{index}\\t{item:3.3f}\\n\")\n",
    "                        else:\n",
    "                            item = label_list[item]\n",
    "                            writer.write(f\"{index}\\t{item}\\n\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "large-final",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e4a03502bf447b85\n",
      "Reusing dataset csv (/home/jupyter-gawron.christian/.cache/huggingface/datasets/csv/default-e4a03502bf447b85/0.0.0)\n",
      "Loading cached processed dataset at /home/jupyter-gawron.christian/.cache/huggingface/datasets/csv/default-e4a03502bf447b85/0.0.0/cache-aa151c082b74cd77.arrow\n",
      "Loading cached processed dataset at /home/jupyter-gawron.christian/.cache/huggingface/datasets/csv/default-e4a03502bf447b85/0.0.0/cache-5f7df1d42ac9f0bc.arrow\n",
      "Loading cached processed dataset at /home/jupyter-gawron.christian/.cache/huggingface/datasets/csv/default-e4a03502bf447b85/0.0.0/cache-52ac9ecece5435b8.arrow\n",
      "Loading cached split indices for dataset at /home/jupyter-gawron.christian/.cache/huggingface/datasets/csv/default-e4a03502bf447b85/0.0.0/cache-7653e2a15d91c773.arrow and /home/jupyter-gawron.christian/.cache/huggingface/datasets/csv/default-e4a03502bf447b85/0.0.0/cache-72ba59075e2d4078.arrow\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import datasets\n",
    "import wandb\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "COLUMNS = ['Sub1_Toxic', 'Sub2_Engaging', 'Sub3_FactClaiming']\n",
    "\n",
    "GERMEVAL2021_RAW = datasets.Dataset.from_csv('GermEval21_Toxic_Train.csv')\n",
    "for id, target in enumerate(COLUMNS):\n",
    "    new_features = GERMEVAL2021_RAW.features.copy()\n",
    "    new_features[target] = datasets.ClassLabel(names=['Other', target[5:]], id=id)\n",
    "    GERMEVAL2021_RAW = GERMEVAL2021_RAW.cast(new_features)\n",
    "    \n",
    "#GERMEVAL2021_RAW.features['Sub1_Toxic']\n",
    "GERMEVAL2021 = GERMEVAL2021_RAW.train_test_split(train_size=0.8)\n",
    "GERMEVAL2021['validation'] = GERMEVAL2021['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-glory",
   "metadata": {},
   "source": [
    "## Add 'toxic' trainig data from GermEval2018 and GermEval2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "healthy-portland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-6687e00c163b9099\n",
      "Reusing dataset csv (/home/jupyter-gawron.christian/.cache/huggingface/datasets/csv/default-6687e00c163b9099/0.0.0)\n",
      "Using custom data configuration default-3b288cbd53cc91cb\n",
      "Reusing dataset csv (/home/jupyter-gawron.christian/.cache/huggingface/datasets/csv/default-3b288cbd53cc91cb/0.0.0)\n",
      "Using custom data configuration default-b4c86526510677f1\n",
      "Reusing dataset csv (/home/jupyter-gawron.christian/.cache/huggingface/datasets/csv/default-b4c86526510677f1/0.0.0)\n",
      "Using custom data configuration default-b832f048e825c62a\n",
      "Reusing dataset csv (/home/jupyter-gawron.christian/.cache/huggingface/datasets/csv/default-b832f048e825c62a/0.0.0)\n",
      "Loading cached processed dataset at /home/jupyter-gawron.christian/.cache/huggingface/datasets/csv/default-e4a03502bf447b85/0.0.0/cache-1e7d6d6822666cbd.arrow\n"
     ]
    }
   ],
   "source": [
    "toxic = [ datasets.Dataset.from_csv(file).remove_columns('Unnamed: 0') for file in ['GermEval2018_training.csv', 'GermEval2019_training.csv', 'GermEval2018_test.csv', 'GermEval2019_test.csv']]\n",
    "\n",
    "def _map(x, y):\n",
    "    return { 'comment_text': x, 'Sub1_Toxic': y}\n",
    "\n",
    "toxic.append(GERMEVAL2021['train'].map(function=_map, input_columns=['comment_text', 'Sub1_Toxic']))\n",
    "\n",
    "toxic_train = datasets.concatenate_datasets(toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "guilty-narrative",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jupyter-gawron.christian/.cache/huggingface/datasets/csv/default-6687e00c163b9099/0.0.0/cache-14ff0660a366ca4e.arrow\n"
     ]
    }
   ],
   "source": [
    "features = toxic_train.features.copy()\n",
    "features['Sub1_Toxic'] = datasets.ClassLabel(names=['Other', 'Toxic'], id=id)\n",
    "toxic_train = toxic_train.cast(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "therapeutic-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['comment_id', 'comment_text', 'Sub1_Toxic', 'Sub2_Engaging', 'Sub3_FactClaiming'],\n",
       "        num_rows: 2595\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['comment_id', 'comment_text', 'Sub1_Toxic', 'Sub2_Engaging', 'Sub3_FactClaiming'],\n",
       "        num_rows: 649\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['comment_id', 'comment_text', 'Sub1_Toxic', 'Sub2_Engaging', 'Sub3_FactClaiming'],\n",
       "        num_rows: 649\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GERMEVAL2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "velvet-breakdown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'comment_id': Value(dtype='int64', id=None),\n",
       "  'comment_text': Value(dtype='string', id=None),\n",
       "  'Sub1_Toxic': ClassLabel(num_classes=2, names=['Other', 'Toxic'], names_file=None, id=0),\n",
       "  'Sub2_Engaging': ClassLabel(num_classes=2, names=['Other', 'Engaging'], names_file=None, id=1),\n",
       "  'Sub3_FactClaiming': ClassLabel(num_classes=2, names=['Other', 'FactClaiming'], names_file=None, id=2)},\n",
       " {'comment_text': Value(dtype='string', id=None),\n",
       "  'Sub1_Toxic': ClassLabel(num_classes=2, names=['Other', 'Toxic'], names_file=None, id=2)})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GERMEVAL2021['test'].features, toxic_train.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "consecutive-hawaii",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['comment_id', 'comment_text', 'label', 'Sub2_Engaging', 'Sub3_FactClaiming'],\n",
      "    num_rows: 2595\n",
      "})\n",
      "06/09/2021 16:38:40 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
      "06/09/2021 16:38:40 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir=out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21, overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=IntervalStrategy.STEPS, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=1.3e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=5, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=0, logging_dir=runs/Jun09_16-38-40_jupiter, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=500, save_strategy=IntervalStrategy.STEPS, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=True, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=100, dataloader_num_workers=0, past_index=-1, run_name=run_Sub1_Toxic_1.3e-05_german-nlp-group/electra-base-german-uncased, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name=length, report_to=['tensorboard', 'wandb'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, _n_gpu=1, mp_parameters=)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:490] 2021-06-09 16:38:40,554 >> loading configuration file https://huggingface.co/german-nlp-group/electra-base-german-uncased/resolve/main/config.json from cache at /home/jupyter-gawron.christian/.cache/huggingface/transformers/8aa9c8c1fb8a4b4472eed9302e63f25f5f4cc692e94603152d3f5a7c59c824ab.f988e04e2ecf3a0c9a557f8386c21c7fd145779fcebf2479a709b6e9264dc4c7\n",
      "[INFO|configuration_utils.py:526] 2021-06-09 16:38:40,557 >> Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 768,\n",
      "  \"finetuning_task\": \"germeval2021\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.5.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:490] 2021-06-09 16:38:40,957 >> loading configuration file https://huggingface.co/german-nlp-group/electra-base-german-uncased/resolve/main/config.json from cache at /home/jupyter-gawron.christian/.cache/huggingface/transformers/8aa9c8c1fb8a4b4472eed9302e63f25f5f4cc692e94603152d3f5a7c59c824ab.f988e04e2ecf3a0c9a557f8386c21c7fd145779fcebf2479a709b6e9264dc4c7\n",
      "[INFO|configuration_utils.py:526] 2021-06-09 16:38:40,961 >> Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.5.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1707] 2021-06-09 16:38:42,951 >> loading file https://huggingface.co/german-nlp-group/electra-base-german-uncased/resolve/main/vocab.txt from cache at /home/jupyter-gawron.christian/.cache/huggingface/transformers/9a370c1c70ceb85831ce9e1e8f03d758f6c7d82f06204d54896befcf6f531a3a.0db1bc27939dbd6aadd28b3d879b1cc07ca2eb8426713910405f100f1aab14bf\n",
      "[INFO|tokenization_utils_base.py:1707] 2021-06-09 16:38:42,953 >> loading file https://huggingface.co/german-nlp-group/electra-base-german-uncased/resolve/main/tokenizer.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1707] 2021-06-09 16:38:42,954 >> loading file https://huggingface.co/german-nlp-group/electra-base-german-uncased/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1707] 2021-06-09 16:38:42,955 >> loading file https://huggingface.co/german-nlp-group/electra-base-german-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1707] 2021-06-09 16:38:42,956 >> loading file https://huggingface.co/german-nlp-group/electra-base-german-uncased/resolve/main/tokenizer_config.json from cache at /home/jupyter-gawron.christian/.cache/huggingface/transformers/fb4a1ed2d5944f91a8fb80f48cdd51c6d08252be817af312c6a65c7bb936e16e.631d352656855628aa0ded8f6e3fca5756979908af3ef4c13b0dbb172ecce5b5\n",
      "[INFO|modeling_utils.py:1052] 2021-06-09 16:38:43,402 >> loading weights file https://huggingface.co/german-nlp-group/electra-base-german-uncased/resolve/main/pytorch_model.bin from cache at /home/jupyter-gawron.christian/.cache/huggingface/transformers/b33e72be695123b268e7f5439d7e486c0827802b648c346b8e70528971c227ad.4432deeffc53e94c26f0dabcdb55ec2efbe78f2c8ca3d695667da5a28ad47a05\n",
      "[WARNING|modeling_utils.py:1160] 2021-06-09 16:38:46,734 >> Some weights of the model checkpoint at german-nlp-group/electra-base-german-uncased were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:1171] 2021-06-09 16:38:46,738 >> Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at german-nlp-group/electra-base-german-uncased and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c84934526c4cad9b6daff8a289a0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "06/09/2021 16:38:47 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /home/jupyter-gawron.christian/.cache/huggingface/datasets/csv/default-e4a03502bf447b85/0.0.0/cache-0cd7e0d38e47f6e3.arrow\n",
      "06/09/2021 16:38:47 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /home/jupyter-gawron.christian/.cache/huggingface/datasets/csv/default-e4a03502bf447b85/0.0.0/cache-0cd7e0d38e47f6e3.arrow\n",
      "06/09/2021 16:38:47 - INFO - __main__ -   Sample 456 of the training set: {'Sub2_Engaging': 1, 'Sub3_FactClaiming': 1, 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'comment_id': 250, 'comment_text': '400 \" Einzelflle jeden Tag in  ! Die unzhligen OPFER sind Gisela Zohren vllig EGAL !  AKTUELL heute in Augsburg :  https://m.augsburger-allgemeine.de/augsburg/Mann-schlaegt-am-Hauptbahnhof-wahllos-auf-Passanten-ein-id53498341.html', 'input_ids': [2, 7224, 768, 3587, 6424, 4413, 3666, 2544, 1755, 2344, 767, 2527, 22482, 6656, 2696, 31480, 2604, 9340, 3118, 6553, 8348, 767, 1, 6100, 3347, 2544, 12705, 792, 1, 5268, 792, 781, 781, 817, 780, 26735, 779, 6485, 780, 2522, 781, 12705, 781, 3910, 779, 5264, 1767, 2681, 779, 2714, 779, 16105, 779, 4169, 3576, 779, 2590, 779, 29712, 779, 2569, 779, 9060, 1807, 16776, 30638, 16776, 1794, 780, 8111, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1, 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "06/09/2021 16:38:47 - INFO - __main__ -   Sample 102 of the training set: {'Sub2_Engaging': 1, 'Sub3_FactClaiming': 1, 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'comment_id': 387, 'comment_text': '...ganz falsch! Heimat ist dort, wo man seine Wurzeln hat. Selbstverstndlich kann man eine neue Heimat finden, aber nur dann, wenn ich bereit bin, einen Teil meiner alten Wurzeln aufzugeben und in meiner neuen Heimat Wurzeln bilde. Wenn ich einen Baum verpflanzen, dann mssen gengend alte Wurzeln vorhanden sein und dieser Baum muss viele neue Wurzeln bilden..... sonst wie er verdorren!', 'input_ids': [2, 780, 780, 780, 3421, 8272, 767, 5768, 2606, 3423, 778, 2996, 2772, 2915, 13291, 2716, 780, 7432, 2793, 2772, 2561, 2880, 5768, 3409, 778, 2821, 2803, 3006, 778, 2822, 2824, 3047, 4716, 778, 2759, 2983, 6294, 4695, 13291, 31186, 2542, 2544, 6294, 3507, 5768, 13291, 3348, 1767, 780, 2822, 2824, 2759, 7239, 4324, 5532, 778, 3006, 3341, 11382, 5713, 13291, 6697, 2897, 2542, 2898, 7239, 3169, 3230, 2880, 13291, 6929, 780, 780, 780, 780, 780, 4660, 2682, 2563, 4399, 2546, 2576, 767, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0, 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "06/09/2021 16:38:47 - INFO - __main__ -   Sample 1126 of the training set: {'Sub2_Engaging': 1, 'Sub3_FactClaiming': 0, 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'comment_id': 208, 'comment_text': 'Ich komme mir inzwischen vor wie in dem Roman \"1984 von Orwell\". Es wird uns vorgegeben, welche Fragen wir stellen drfen. Geht\\'s noch ...', 'input_ids': [2, 2824, 5714, 3903, 6050, 2640, 2682, 2544, 2639, 6279, 768, 11477, 2589, 2966, 15843, 768, 780, 2647, 2713, 2961, 27362, 778, 3253, 4233, 2623, 3857, 5030, 780, 3520, 773, 823, 2827, 780, 780, 780, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0, 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:491] 2021-06-09 16:38:52,069 >> The following columns in the training set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: Sub2_Engaging, comment_id, Sub3_FactClaiming, comment_text.\n",
      "[INFO|trainer.py:491] 2021-06-09 16:38:52,074 >> The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: Sub2_Engaging, comment_id, Sub3_FactClaiming, comment_text.\n",
      "[INFO|trainer.py:402] 2021-06-09 16:38:52,075 >> Using amp fp16 backend\n",
      "[INFO|trainer.py:1013] 2021-06-09 16:38:52,278 >> ***** Running training *****\n",
      "[INFO|trainer.py:1014] 2021-06-09 16:38:52,279 >>   Num examples = 2595\n",
      "[INFO|trainer.py:1015] 2021-06-09 16:38:52,281 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1016] 2021-06-09 16:38:52,282 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1017] 2021-06-09 16:38:52,283 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1018] 2021-06-09 16:38:52,284 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1019] 2021-06-09 16:38:52,285 >>   Total optimization steps = 1625\n",
      "[INFO|integrations.py:587] 2021-06-09 16:38:52,307 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/09/2021 16:38:52 - ERROR - wandb.jupyter -   Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcgawron\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">run_Sub1_Toxic_1.3e-05_german-nlp-group/electra-base-german-uncased</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/cgawron/GermEval_2021\" target=\"_blank\">https://wandb.ai/cgawron/GermEval_2021</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/cgawron/GermEval_2021/runs/cu2k68f9\" target=\"_blank\">https://wandb.ai/cgawron/GermEval_2021/runs/cu2k68f9</a><br/>\n",
       "                Run data is saved locally in <code>/home/jupyter-gawron.christian/GermEval_2021/wandb/run-20210609_163852-cu2k68f9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1625' max='1625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1625/1625 05:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Other</th>\n",
       "      <th>Recall Other</th>\n",
       "      <th>F1 Other</th>\n",
       "      <th>Precision Toxic</th>\n",
       "      <th>Recall Toxic</th>\n",
       "      <th>F1 Toxic</th>\n",
       "      <th>Precision Ma</th>\n",
       "      <th>Recall Ma</th>\n",
       "      <th>F1 Ma</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.611692</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.330508</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>3.995100</td>\n",
       "      <td>162.449000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.573231</td>\n",
       "      <td>0.714946</td>\n",
       "      <td>0.764069</td>\n",
       "      <td>0.822844</td>\n",
       "      <td>0.792368</td>\n",
       "      <td>0.593583</td>\n",
       "      <td>0.504545</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.678826</td>\n",
       "      <td>0.663695</td>\n",
       "      <td>0.671175</td>\n",
       "      <td>3.949900</td>\n",
       "      <td>164.306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.579402</td>\n",
       "      <td>0.714946</td>\n",
       "      <td>0.735521</td>\n",
       "      <td>0.888112</td>\n",
       "      <td>0.804646</td>\n",
       "      <td>0.633588</td>\n",
       "      <td>0.377273</td>\n",
       "      <td>0.472934</td>\n",
       "      <td>0.684555</td>\n",
       "      <td>0.632692</td>\n",
       "      <td>0.657602</td>\n",
       "      <td>3.923800</td>\n",
       "      <td>165.401000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.635249</td>\n",
       "      <td>0.691834</td>\n",
       "      <td>0.773270</td>\n",
       "      <td>0.755245</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.658374</td>\n",
       "      <td>0.661713</td>\n",
       "      <td>0.660039</td>\n",
       "      <td>3.953200</td>\n",
       "      <td>164.172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.558500</td>\n",
       "      <td>0.590064</td>\n",
       "      <td>0.719569</td>\n",
       "      <td>0.741683</td>\n",
       "      <td>0.883450</td>\n",
       "      <td>0.806383</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.491620</td>\n",
       "      <td>0.689682</td>\n",
       "      <td>0.641725</td>\n",
       "      <td>0.664840</td>\n",
       "      <td>3.960700</td>\n",
       "      <td>163.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.558500</td>\n",
       "      <td>0.610463</td>\n",
       "      <td>0.684129</td>\n",
       "      <td>0.821839</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.736165</td>\n",
       "      <td>0.524917</td>\n",
       "      <td>0.718182</td>\n",
       "      <td>0.606526</td>\n",
       "      <td>0.673378</td>\n",
       "      <td>0.692424</td>\n",
       "      <td>0.682768</td>\n",
       "      <td>3.932300</td>\n",
       "      <td>165.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.558500</td>\n",
       "      <td>0.686655</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.895105</td>\n",
       "      <td>0.812698</td>\n",
       "      <td>0.661654</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.498584</td>\n",
       "      <td>0.702920</td>\n",
       "      <td>0.647552</td>\n",
       "      <td>0.674101</td>\n",
       "      <td>3.911100</td>\n",
       "      <td>165.937000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.558500</td>\n",
       "      <td>0.762967</td>\n",
       "      <td>0.713405</td>\n",
       "      <td>0.798526</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.777512</td>\n",
       "      <td>0.570248</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>0.684387</td>\n",
       "      <td>0.692424</td>\n",
       "      <td>0.688382</td>\n",
       "      <td>3.898500</td>\n",
       "      <td>166.476000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.558500</td>\n",
       "      <td>0.720259</td>\n",
       "      <td>0.734977</td>\n",
       "      <td>0.790068</td>\n",
       "      <td>0.815851</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.616505</td>\n",
       "      <td>0.577273</td>\n",
       "      <td>0.596244</td>\n",
       "      <td>0.703286</td>\n",
       "      <td>0.696562</td>\n",
       "      <td>0.699908</td>\n",
       "      <td>3.956000</td>\n",
       "      <td>164.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.769567</td>\n",
       "      <td>0.724191</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.806527</td>\n",
       "      <td>0.794489</td>\n",
       "      <td>0.599034</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.580796</td>\n",
       "      <td>0.690920</td>\n",
       "      <td>0.685082</td>\n",
       "      <td>0.687988</td>\n",
       "      <td>3.917900</td>\n",
       "      <td>165.649000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.877825</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.864802</td>\n",
       "      <td>0.807399</td>\n",
       "      <td>0.635220</td>\n",
       "      <td>0.459091</td>\n",
       "      <td>0.532982</td>\n",
       "      <td>0.696181</td>\n",
       "      <td>0.661946</td>\n",
       "      <td>0.678632</td>\n",
       "      <td>3.920200</td>\n",
       "      <td>165.553000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.911801</td>\n",
       "      <td>0.725732</td>\n",
       "      <td>0.759834</td>\n",
       "      <td>0.855478</td>\n",
       "      <td>0.804825</td>\n",
       "      <td>0.626506</td>\n",
       "      <td>0.472727</td>\n",
       "      <td>0.538860</td>\n",
       "      <td>0.693170</td>\n",
       "      <td>0.664103</td>\n",
       "      <td>0.678325</td>\n",
       "      <td>3.946400</td>\n",
       "      <td>164.453000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.920776</td>\n",
       "      <td>0.734977</td>\n",
       "      <td>0.777538</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.807175</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.531818</td>\n",
       "      <td>0.576355</td>\n",
       "      <td>0.703285</td>\n",
       "      <td>0.685490</td>\n",
       "      <td>0.694273</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>162.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.975792</td>\n",
       "      <td>0.734977</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.805869</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>0.703091</td>\n",
       "      <td>0.688811</td>\n",
       "      <td>0.695878</td>\n",
       "      <td>4.017000</td>\n",
       "      <td>161.564000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>1.005204</td>\n",
       "      <td>0.733436</td>\n",
       "      <td>0.781938</td>\n",
       "      <td>0.827506</td>\n",
       "      <td>0.804077</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.583133</td>\n",
       "      <td>0.701226</td>\n",
       "      <td>0.688753</td>\n",
       "      <td>0.694933</td>\n",
       "      <td>3.937800</td>\n",
       "      <td>164.811000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>1.023544</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.788155</td>\n",
       "      <td>0.806527</td>\n",
       "      <td>0.797235</td>\n",
       "      <td>0.604762</td>\n",
       "      <td>0.577273</td>\n",
       "      <td>0.590698</td>\n",
       "      <td>0.696458</td>\n",
       "      <td>0.691900</td>\n",
       "      <td>0.694172</td>\n",
       "      <td>3.955100</td>\n",
       "      <td>164.093000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:1865] 2021-06-09 16:39:12,841 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1866] 2021-06-09 16:39:12,844 >>   Num examples = 649\n",
      "[INFO|trainer.py:1867] 2021-06-09 16:39:12,845 >>   Batch size = 8\n",
      "[INFO|trainer.py:1865] 2021-06-09 16:39:32,542 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1866] 2021-06-09 16:39:32,546 >>   Num examples = 649\n",
      "[INFO|trainer.py:1867] 2021-06-09 16:39:32,547 >>   Batch size = 8\n",
      "[INFO|trainer.py:1865] 2021-06-09 16:39:52,575 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1866] 2021-06-09 16:39:52,579 >>   Num examples = 649\n",
      "[INFO|trainer.py:1867] 2021-06-09 16:39:52,580 >>   Batch size = 8\n",
      "[INFO|trainer.py:1865] 2021-06-09 16:40:12,050 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1866] 2021-06-09 16:40:12,054 >>   Num examples = 649\n",
      "[INFO|trainer.py:1867] 2021-06-09 16:40:12,055 >>   Batch size = 8\n",
      "[INFO|trainer.py:1865] 2021-06-09 16:40:33,538 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1866] 2021-06-09 16:40:33,541 >>   Num examples = 649\n",
      "[INFO|trainer.py:1867] 2021-06-09 16:40:33,543 >>   Batch size = 8\n",
      "[INFO|trainer.py:1648] 2021-06-09 16:40:37,502 >> Saving model checkpoint to out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/checkpoint-500\n",
      "[INFO|configuration_utils.py:329] 2021-06-09 16:40:37,507 >> Configuration saved in out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/checkpoint-500/config.json\n",
      "[INFO|modeling_utils.py:831] 2021-06-09 16:40:38,398 >> Model weights saved in out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/checkpoint-500/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:1901] 2021-06-09 16:40:38,401 >> tokenizer config file saved in out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/checkpoint-500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1907] 2021-06-09 16:40:38,403 >> Special tokens file saved in out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/checkpoint-500/special_tokens_map.json\n",
      "[INFO|trainer.py:1865] 2021-06-09 16:40:55,641 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1866] 2021-06-09 16:40:55,645 >>   Num examples = 649\n",
      "[INFO|trainer.py:1867] 2021-06-09 16:40:55,647 >>   Batch size = 8\n",
      "[INFO|trainer.py:1865] 2021-06-09 16:41:15,205 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1866] 2021-06-09 16:41:15,208 >>   Num examples = 649\n",
      "[INFO|trainer.py:1867] 2021-06-09 16:41:15,210 >>   Batch size = 8\n",
      "[INFO|trainer.py:1865] 2021-06-09 16:41:34,803 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1866] 2021-06-09 16:41:34,806 >>   Num examples = 649\n",
      "[INFO|trainer.py:1867] 2021-06-09 16:41:34,808 >>   Batch size = 8\n",
      "[INFO|trainer.py:1865] 2021-06-09 16:41:54,279 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1866] 2021-06-09 16:41:54,282 >>   Num examples = 649\n",
      "[INFO|trainer.py:1867] 2021-06-09 16:41:54,284 >>   Batch size = 8\n",
      "[INFO|trainer.py:1865] 2021-06-09 16:42:15,891 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1866] 2021-06-09 16:42:15,895 >>   Num examples = 649\n",
      "[INFO|trainer.py:1867] 2021-06-09 16:42:15,897 >>   Batch size = 8\n",
      "[INFO|trainer.py:1648] 2021-06-09 16:42:19,813 >> Saving model checkpoint to out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/checkpoint-1000\n",
      "[INFO|configuration_utils.py:329] 2021-06-09 16:42:19,817 >> Configuration saved in out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/checkpoint-1000/config.json\n",
      "[INFO|modeling_utils.py:831] 2021-06-09 16:42:20,685 >> Model weights saved in out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/checkpoint-1000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:1901] 2021-06-09 16:42:20,688 >> tokenizer config file saved in out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/checkpoint-1000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1907] 2021-06-09 16:42:20,690 >> Special tokens file saved in out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/checkpoint-1000/special_tokens_map.json\n",
      "[INFO|trainer.py:1865] 2021-06-09 16:42:38,049 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1866] 2021-06-09 16:42:38,053 >>   Num examples = 649\n",
      "[INFO|trainer.py:1867] 2021-06-09 16:42:38,055 >>   Batch size = 8\n",
      "[INFO|trainer.py:1865] 2021-06-09 16:42:57,774 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1866] 2021-06-09 16:42:57,777 >>   Num examples = 649\n",
      "[INFO|trainer.py:1867] 2021-06-09 16:42:57,779 >>   Batch size = 8\n",
      "[INFO|trainer.py:1865] 2021-06-09 16:43:17,188 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1866] 2021-06-09 16:43:17,191 >>   Num examples = 649\n",
      "[INFO|trainer.py:1867] 2021-06-09 16:43:17,192 >>   Batch size = 8\n",
      "[INFO|trainer.py:1865] 2021-06-09 16:43:36,720 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1866] 2021-06-09 16:43:36,723 >>   Num examples = 649\n",
      "[INFO|trainer.py:1867] 2021-06-09 16:43:36,724 >>   Batch size = 8\n",
      "[INFO|trainer.py:1865] 2021-06-09 16:43:58,062 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1866] 2021-06-09 16:43:58,066 >>   Num examples = 649\n",
      "[INFO|trainer.py:1867] 2021-06-09 16:43:58,067 >>   Batch size = 8\n",
      "[INFO|trainer.py:1648] 2021-06-09 16:44:02,005 >> Saving model checkpoint to out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/checkpoint-1500\n",
      "[INFO|configuration_utils.py:329] 2021-06-09 16:44:02,010 >> Configuration saved in out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/checkpoint-1500/config.json\n",
      "[INFO|modeling_utils.py:831] 2021-06-09 16:44:02,868 >> Model weights saved in out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/checkpoint-1500/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:1901] 2021-06-09 16:44:02,871 >> tokenizer config file saved in out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/checkpoint-1500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1907] 2021-06-09 16:44:02,873 >> Special tokens file saved in out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/checkpoint-1500/special_tokens_map.json\n",
      "[INFO|trainer.py:1865] 2021-06-09 16:44:19,970 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1866] 2021-06-09 16:44:19,974 >>   Num examples = 649\n",
      "[INFO|trainer.py:1867] 2021-06-09 16:44:19,975 >>   Batch size = 8\n",
      "[INFO|trainer.py:1196] 2021-06-09 16:44:27,743 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:402] 2021-06-09 16:44:27,918 >> Using amp fp16 backend\n",
      "[INFO|trainer.py:1648] 2021-06-09 16:44:28,013 >> Saving model checkpoint to /tmp/tmp94_6ik9r\n",
      "[INFO|configuration_utils.py:329] 2021-06-09 16:44:28,015 >> Configuration saved in /tmp/tmp94_6ik9r/config.json\n",
      "[INFO|modeling_utils.py:831] 2021-06-09 16:44:28,854 >> Model weights saved in /tmp/tmp94_6ik9r/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:1901] 2021-06-09 16:44:28,856 >> tokenizer config file saved in /tmp/tmp94_6ik9r/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1907] 2021-06-09 16:44:28,858 >> Special tokens file saved in /tmp/tmp94_6ik9r/special_tokens_map.json\n",
      "[INFO|trainer.py:1648] 2021-06-09 16:44:37,172 >> Saving model checkpoint to out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21\n",
      "[INFO|configuration_utils.py:329] 2021-06-09 16:44:37,176 >> Configuration saved in out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/config.json\n",
      "[INFO|modeling_utils.py:831] 2021-06-09 16:44:38,010 >> Model weights saved in out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:1901] 2021-06-09 16:44:38,012 >> tokenizer config file saved in out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1907] 2021-06-09 16:44:38,014 >> Special tokens file saved in out_Sub1_Toxic_german-nlp-group/electra-base-german-uncased_nur_21/special_tokens_map.json\n",
      "[INFO|trainer_pt_utils.py:722] 2021-06-09 16:44:38,046 >> ***** train metrics *****\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:38,048 >>   epoch                      =        5.0\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:38,049 >>   init_mem_cpu_alloc_delta   =     1954MB\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:38,050 >>   init_mem_cpu_peaked_delta  =      311MB\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:38,052 >>   init_mem_gpu_alloc_delta   =      424MB\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:38,054 >>   init_mem_gpu_peaked_delta  =        0MB\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:38,057 >>   total_flos                 =  1032058GF\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:38,059 >>   train_mem_cpu_alloc_delta  =       68MB\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:38,062 >>   train_mem_cpu_peaked_delta =      424MB\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:38,064 >>   train_mem_gpu_alloc_delta  =     1314MB\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:38,066 >>   train_mem_gpu_peaked_delta =        0MB\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:38,067 >>   train_runtime              = 0:05:35.45\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:38,069 >>   train_samples              =       2595\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:38,071 >>   train_samples_per_second   =      4.844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/09/2021 16:44:38 - INFO - __main__ -   *** Evaluate ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:491] 2021-06-09 16:44:38,184 >> The following columns in the evaluation set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: Sub2_Engaging, comment_id, Sub3_FactClaiming, comment_text.\n",
      "[INFO|trainer.py:1865] 2021-06-09 16:44:38,187 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1866] 2021-06-09 16:44:38,189 >>   Num examples = 649\n",
      "[INFO|trainer.py:1867] 2021-06-09 16:44:38,190 >>   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer_pt_utils.py:722] 2021-06-09 16:44:42,287 >> ***** eval metrics *****\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,295 >>   epoch                     =        5.0\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,297 >>   eval_accuracy             =     0.7273\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,298 >>   eval_f1_Other             =     0.7968\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,299 >>   eval_f1_Toxic             =     0.5855\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,300 >>   eval_f1_ma                =     0.6915\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,302 >>   eval_loss                 =     1.0229\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,303 >>   eval_mem_cpu_alloc_delta  =        0MB\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,304 >>   eval_mem_cpu_peaked_delta =        0MB\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,305 >>   eval_mem_gpu_alloc_delta  =        0MB\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,306 >>   eval_mem_gpu_peaked_delta =       33MB\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,307 >>   eval_precision_Other      =     0.7851\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,308 >>   eval_precision_Toxic      =     0.6039\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,309 >>   eval_precision_ma         =     0.6945\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,310 >>   eval_recall_Other         =     0.8089\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,311 >>   eval_recall_Toxic         =     0.5682\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,312 >>   eval_recall_ma            =     0.6885\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,313 >>   eval_runtime              = 0:00:03.96\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,313 >>   eval_samples              =        649\n",
      "[INFO|trainer_pt_utils.py:727] 2021-06-09 16:44:42,314 >>   eval_samples_per_second   =    163.534\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1466911<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:16:44.302491, resuming normal operation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 424.79MB of 424.79MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/jupyter-gawron.christian/GermEval_2021/wandb/run-20210609_163852-cu2k68f9/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/jupyter-gawron.christian/GermEval_2021/wandb/run-20210609_163852-cu2k68f9/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td>1.02287</td></tr><tr><td>eval/accuracy</td><td>0.72727</td></tr><tr><td>eval/precision_Other</td><td>0.78507</td></tr><tr><td>eval/recall_Other</td><td>0.80886</td></tr><tr><td>eval/f1_Other</td><td>0.79679</td></tr><tr><td>eval/precision_Toxic</td><td>0.60386</td></tr><tr><td>eval/recall_Toxic</td><td>0.56818</td></tr><tr><td>eval/f1_Toxic</td><td>0.58548</td></tr><tr><td>eval/precision_ma</td><td>0.69447</td></tr><tr><td>eval/recall_ma</td><td>0.68852</td></tr><tr><td>eval/f1_ma</td><td>0.69148</td></tr><tr><td>eval/runtime</td><td>3.9686</td></tr><tr><td>eval/samples_per_second</td><td>163.534</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>1625</td></tr><tr><td>_runtime</td><td>350</td></tr><tr><td>_timestamp</td><td>1623249882</td></tr><tr><td>_step</td><td>20</td></tr><tr><td>train/loss</td><td>0.2389</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/train_runtime</td><td>335.459</td></tr><tr><td>train/train_samples_per_second</td><td>4.844</td></tr><tr><td>train/total_flos</td><td>1108164860582400.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td></td></tr><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/precision_Other</td><td></td></tr><tr><td>eval/recall_Other</td><td></td></tr><tr><td>eval/f1_Other</td><td></td></tr><tr><td>eval/precision_Toxic</td><td></td></tr><tr><td>eval/recall_Toxic</td><td></td></tr><tr><td>eval/f1_Toxic</td><td></td></tr><tr><td>eval/precision_ma</td><td></td></tr><tr><td>eval/recall_ma</td><td></td></tr><tr><td>eval/f1_ma</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>_runtime</td><td></td></tr><tr><td>_timestamp</td><td></td></tr><tr><td>_step</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/train_runtime</td><td></td></tr><tr><td>train/train_samples_per_second</td><td></td></tr><tr><td>train/total_flos</td><td></td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 1 media file(s), 6 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">run_Sub1_Toxic_1.3e-05_german-nlp-group/electra-base-german-uncased</strong>: <a href=\"https://wandb.ai/cgawron/GermEval_2021/runs/cu2k68f9\" target=\"_blank\">https://wandb.ai/cgawron/GermEval_2021/runs/cu2k68f9</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"german-nlp-group/electra-base-german-uncased\"\n",
    "#model_name = \"deepset/gbert-large\"\n",
    "lr = 1.3e-5\n",
    "\n",
    "model = {}\n",
    "\n",
    "#for target in COLUMNS:\n",
    "for target in ['Sub1_Toxic']:\n",
    "    germeval2021 = GERMEVAL2021\n",
    "    #germeval2021['train'] = toxic_train\n",
    "    germeval2021 = germeval2021.rename_column(target, 'label')\n",
    "    print(germeval2021[\"train\"])\n",
    "\n",
    "    config = {\n",
    "        \"model_name_or_path\": model_name,\n",
    "        \"task_name\": \"GermEval2021\",\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"evaluation_strategy\": \"steps\",\n",
    "        \"eval_steps\": 100,\n",
    "        #\"max_seq_length\": 255,\n",
    "        \"learning_rate\": lr,\n",
    "        \"fp16\": True,\n",
    "        \"num_train_epochs\": 5,\n",
    "        #\"max_steps\": 1510,\n",
    "        \"overwrite_output\": True,\n",
    "        \"output_dir\": f\"out_{target}_{model_name}_nur_21\",\n",
    "        \"run_name\": f\"run_{target}_{lr}_{model_name}\"\n",
    "        #\"resume_from_checkpoint\": 1500\n",
    "    }\n",
    "\n",
    "    model[target] = main(config)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-special",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-dictionary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p_off, r_off, f_off, p_oth, r_oth, f_oth) = (0.808057, 0.567388, 0.666667, 0.806548, 0.930472, 0.864089)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_macro = 0.5 * (p_off + p_oth)\n",
    "r_macro = 0.5 * (r_off + r_oth)\n",
    "f_macro = 2 * p_macro * r_macro / (p_macro + r_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-salmon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
